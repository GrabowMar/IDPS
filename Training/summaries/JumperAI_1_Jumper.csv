Steps,Policy/Entropy,High Score,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Is Training
10000,1.1998097,11.0,63.23717948717949,-5.870336,-48.91612903225806,-48.91612903225806,231.74953,0.13220659,0.00029996978,1.0
20000,0.8711972,23.0,130.76388888888889,-12.095669,-47.32876712328767,-47.32876712328767,77.7404,0.13278016,0.0002999106,1.0
30000,0.864227,None,273.4736842105263,-10.344997,-43.44736842105263,-43.44736842105263,40.11531,0.13378088,0.00029984995,1.0
40000,0.67961746,35.0,303.3636363636364,-7.2109094,-42.42424242424242,-42.42424242424242,41.726852,0.13267489,0.00029979064,1.0
50000,0.66249293,None,305.03225806451616,-5.795356,-42.03225806451613,-42.03225806451613,45.876217,0.13140525,0.00029972964,1.0
60000,0.62070805,56.0,293.74285714285713,-5.2253623,-42.74285714285714,-42.74285714285714,51.33356,0.1328197,0.00029966957,1.0
70000,0.68291694,None,349.0689655172414,-4.518014,-42.172413793103445,-42.172413793103445,43.671642,0.13356866,0.00029960988,1.0
80000,0.48816776,None,431.69565217391306,-2.9163625,-39.69565217391305,-39.69565217391305,37.296062,0.12910946,0.00029955062,1.0
90000,0.51262784,None,143.37142857142857,-6.2129183,-47.44285714285714,-47.44285714285714,94.41843,0.13160805,0.00029948956,1.0
100000,0.72000504,None,113.42528735632185,-15.72023,-48.14942528735632,-48.14942528735632,89.0338,0.13401407,0.00029943045,1.0
110000,0.71370155,None,237.90243902439025,-14.520316,-43.853658536585364,-43.853658536585364,47.32841,0.12986481,0.00029937027,1.0
120000,0.7968898,None,262.6923076923077,-8.690174,-43.89473684210526,-43.89473684210526,42.936733,0.1321173,0.00029930982,1.0
130000,0.5486058,None,318.03225806451616,-5.7056756,-42.25,-42.25,46.40013,0.13004468,0.0002992497,1.0
140000,0.55153465,None,330.7586206896552,-5.288649,-42.13793103448276,-42.13793103448276,45.168396,0.13086794,0.00029919026,1.0
